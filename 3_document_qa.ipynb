{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "TbEyM5LG7v"
      },
      "source": [
        "# Dependencies\n",
        "\n",
        "1. PyPDFLoader depends upon pypdf to process the pdfs\n",
        "2. YoutubeAudioLoader depends upon yt_dlp, pydub and librosa\n",
        "    - yt_dlp: To download the relevant audio transcripts of youtube videos\n",
        "    - pydub: To split the audio to adhere to OpenAI Whisper's 25mb limit\n",
        "\n",
        "(Here is the relevant list of all other document loaders)[https://python.langchain.com/docs/integrations/document_loaders]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "jROmUVO56V"
      },
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf_loader = PyPDFLoader('docs/pdf/hyperion.pdf')\n",
        "pdf_docs = pdf_loader.load()\n",
        "pdf_docs = pdf_docs\n",
        "print(f'Number of pages: {len(pdf_docs)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of pages: 570\n"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "S1hZu5RQBT"
      },
      "source": [
        "# Possible Bugs\n",
        "\n",
        "I've encountered the recent versions of openai (>=1.0.0) to be incompatible with the latest version of langchain (0.0.333), as a result I've had to make the following changes:\n",
        "\n",
        "1. run `openai migrate <path-to-langchain>/document_loaders/parsers/audio.py` replace `<path-to-langchain>` with the correct path to langchain\n",
        "2. change line 66 in `<path-to-langchain>/document_loaders/parsers/audio.py` to `transcript = client.audio.transcriptions.create(model=\"whisper-1\", file=file_obj)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "XoRGWAQZ64"
      },
      "source": [
        "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
        "from langchain.document_loaders.generic import GenericLoader\n",
        "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
        "\n",
        "url = 'https://youtu.be/_PPWWRV6gbA?si=hQFeGBgt6yawfuPI'\n",
        "youtube_loader = GenericLoader(YoutubeAudioLoader([url],'docs/youtube'), OpenAIWhisperParser())\n",
        "youtube_docs = youtube_loader.load()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "Ms4oGwnKyA"
      },
      "source": [
        "# Preprocessing & Splitting\n",
        "\n",
        "### Preprocessing\n",
        "1. The `PyPDFLoader` returns a list of `Document` objects, each of which has a `page_content` and `metadata` attribute\n",
        "2. The `page_content` attribute is then preprocessed to add `#` before each chapter number\n",
        "3. The `metadata` attribute is then updated to include the chapter number, story and character name\n",
        "\n",
        "\n",
        "### Splitting\n",
        "Langchain provides us with numerous splitting options, some of most common ones are:\n",
        "1. `CharacterTextSplitter`: Splits the text into chunks of a fixed size, with a fixed overlap\n",
        "2. `RecursiveCharacterTextSplitter`: Simillar to `CharacterTextSplitter` but recursively splits the text into smaller chunks\n",
        "3. `MarkdownTextSplitter`: Splits the text into chunks based on markdown headers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Cc7oqpJZQe"
      },
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import re\n",
        "\n",
        "def preprocess_pdf(docs):\n",
        "    sc_mapping = {'Priest/Lenar Hoyt': [35, 114], 'Soldier/Fedmahn Kassad': [144, 204], 'Poet/Martin Silenus': [210, 271], 'Scholar/Sol Weintraub': [285, 356], 'Detective/Brawne Lamia': [376, 470], 'Consul/Consul': [484, 541]}\n",
        "    chapter = 0\n",
        "    for page in docs:\n",
        "        page_content = re.sub(r'^\\s*(\\d+)\\s*$', r'#\\1', page.page_content, flags=re.MULTILINE)\n",
        "        if '#' in page_content: chapter = int(page_content.split('#')[1].split('\\n')[0])\n",
        "        for k,v in sc_mapping.items():\n",
        "            if v[0] <= page.metadata['page']+1 <= v[1]:\n",
        "                story = k.split('/')[0]\n",
        "                character = k.split('/')[1]\n",
        "                break\n",
        "            story, character = 'Plot', 'None'\n",
        "        page.page_content = page_content\n",
        "        page.metadata['chapter'] = chapter\n",
        "        page.metadata['story'] = story\n",
        "        page.metadata['character'] = character\n",
        "        page.metadata['page'] += 1\n",
        "    return docs\n",
        "\n",
        "pdf_docs = preprocess_pdf(pdf_docs)\n",
        "pdf_docs_copy = pdf_docs.copy()\n",
        "for _ in range(3):\n",
        "    pdf_docs += pdf_docs_copy.copy()\n",
        "print(f'Number of pages: {len(pdf_docs)}')\n",
        "print(f'random page: {pdf_docs[320].page_content[:100]}')\n",
        "print(f'random page metadata: {pdf_docs[320].metadata}')\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,\n",
        "    chunk_overlap=150,\n",
        "    separators=['#', '\\n', '\"', ' ', '']\n",
        ")\n",
        "splits = text_splitter.split_documents(pdf_docs)\n",
        "print(f'Number of splits: {len(splits)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of pages: 2280\nrandom page: last contact, Arundez had aged but little\u2014Sol guessed that\nhe was still in his late twenties. But th\nrandom page metadata: {'source': 'docs/pdf/hyperion.pdf', 'page': 321, 'chapter': 4, 'story': 'Scholar', 'character': 'Sol Weintraub'}\nNumber of splits: 4340\n"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "WedNBTtFMw"
      },
      "source": [
        "# Embedding & Vectorstore\n",
        "\n",
        "### Embedding\n",
        "Langchain provides us with numerous vectorization options, some of most common ones are:\n",
        "1. `HuggingFaceEmbeddings`: Uses the HuggingFace transformers library to generate embeddings\n",
        "2. `OpenAIEmbeddings`: Uses the OpenAI GPT library to generate embeddings\n",
        "\n",
        "We chose to use the `HuggingFaceEmbeddings` as OpenAI was rate limiting the number of requests we could make to their API\n",
        "\n",
        "### Vectorstore\n",
        "A vectorstore is a database of embeddings which corresponds to a set of documents. Langchain provides us with numerous vectorstore options, some of most common ones are:\n",
        "1. `FAISS`: Uses the FAISS library to generate vectorstores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "olTlw6cSCu"
      },
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import os\n",
        "\n",
        "def retrieve_vectorstore(documents):\n",
        "    store_name, _ = os.path.splitext(os.path.basename(documents[0].metadata['source']))\n",
        "    store_path = os.path.join(r'docs/vectorstores', store_name)\n",
        "    if os.path.exists(store_path):\n",
        "        return FAISS.load_local(store_path, HuggingFaceEmbeddings())\n",
        "    else:\n",
        "        vectorstore = FAISS.from_documents(documents=documents, embedding=HuggingFaceEmbeddings())\n",
        "        vectorstore.save_local(store_path)\n",
        "        return vectorstore\n",
        "\n",
        "vectordb = retrieve_vectorstore(splits)\n",
        "query = 'Who are the Outcasters?'\n",
        "print(vectordb.similarity_search('Outcasters?', n=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)\nCell \u001b[0;32mIn[23], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         vectorstore\u001b[38;5;241m.\u001b[39msave_local(store_path)\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore\n\u001b[0;32m---> 15\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m retrieve_vectorstore(splits)\n\u001b[1;32m     16\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWho are the Outcasters?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(vectordb\u001b[38;5;241m.\u001b[39msimilarity_search(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutcasters?\u001b[39m\u001b[38;5;124m'\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\nCell \u001b[0;32mIn[23], line 11\u001b[0m, in \u001b[0;36mretrieve_vectorstore\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FAISS\u001b[38;5;241m.\u001b[39mload_local(store_path, HuggingFaceEmbeddings())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     vectorstore \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(documents\u001b[38;5;241m=\u001b[39mdocuments, embedding\u001b[38;5;241m=\u001b[39mHuggingFaceEmbeddings(show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     12\u001b[0m     vectorstore\u001b[38;5;241m.\u001b[39msave_local(store_path)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore\n\nFile \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/embeddings/huggingface.py:56\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the sentence_transformer.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\nFile \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n\n\u001b[0;31mValidationError\u001b[0m: 1 validation error for HuggingFaceEmbeddings\nshow_progress_bar\n  extra fields not permitted (type=value_error.extra)\n"
        }
      ],
      "execution_count": 3
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
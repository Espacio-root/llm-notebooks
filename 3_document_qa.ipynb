{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "TbEyM5LG7v"
      },
      "source": [
        "# Dependencies\n",
        "\n",
        "1. PyPDFLoader depends upon pypdf to process the pdfs\n",
        "2. YoutubeAudioLoader depends upon yt_dlp, pydub and librosa\n",
        "    - yt_dlp: To download the relevant audio transcripts of youtube videos\n",
        "    - pydub: To split the audio to adhere to OpenAI Whisper's 25mb limit\n",
        "\n",
        "(Here is the relevant list of all other document loaders)[https://python.langchain.com/docs/integrations/document_loaders]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "jROmUVO56V"
      },
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf_loader = PyPDFLoader('docs/pdf/hyperion.pdf')\n",
        "pdf_docs = pdf_loader.load()\n",
        "pdf_docs = pdf_docs\n",
        "print(f'Number of pages: {len(pdf_docs)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of pages: 570\n"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "S1hZu5RQBT"
      },
      "source": [
        "# Possible Bugs\n",
        "\n",
        "I've encountered the recent versions of openai (>=1.0.0) to be incompatible with the latest version of langchain (0.0.333), as a result I've had to make the following changes:\n",
        "\n",
        "1. run `openai migrate <path-to-langchain>/document_loaders/parsers/audio.py` replace `<path-to-langchain>` with the correct path to langchain\n",
        "2. change line 66 in `<path-to-langchain>/document_loaders/parsers/audio.py` to `transcript = client.audio.transcriptions.create(model=\"whisper-1\", file=file_obj)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "XoRGWAQZ64"
      },
      "source": [
        "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
        "from langchain.document_loaders.generic import GenericLoader\n",
        "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
        "\n",
        "url = 'https://youtu.be/_PPWWRV6gbA?si=hQFeGBgt6yawfuPI'\n",
        "youtube_loader = GenericLoader(YoutubeAudioLoader([url],'docs/youtube'), OpenAIWhisperParser())\n",
        "youtube_docs = youtube_loader.load()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "Ms4oGwnKyA"
      },
      "source": [
        "# Preprocessing & Splitting\n",
        "\n",
        "### Preprocessing\n",
        "1. The `PyPDFLoader` returns a list of `Document` objects, each of which has a `page_content` and `metadata` attribute\n",
        "2. The `page_content` attribute is then preprocessed to add `#` before each chapter number\n",
        "3. The `metadata` attribute is then updated to include the chapter number, story and character name\n",
        "\n",
        "\n",
        "### Splitting\n",
        "Langchain provides us with numerous splitting options, some of most common ones are:\n",
        "1. `CharacterTextSplitter`: Splits the text into chunks of a fixed size, with a fixed overlap\n",
        "2. `RecursiveCharacterTextSplitter`: Simillar to `CharacterTextSplitter` but recursively splits the text into smaller chunks\n",
        "3. `MarkdownTextSplitter`: Splits the text into chunks based on markdown headers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Cc7oqpJZQe"
      },
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import re\n",
        "\n",
        "def preprocess_pdf(docs):\n",
        "    sc_mapping = {'Priest/Lenar Hoyt': [35, 114], 'Soldier/Fedmahn Kassad': [144, 204], 'Poet/Martin Silenus': [210, 271], 'Scholar/Sol Weintraub': [285, 356], 'Detective/Brawne Lamia': [376, 470], 'Consul/Consul': [484, 541]}\n",
        "    chapter = 0\n",
        "    for page in docs:\n",
        "        page_content = re.sub(r'^\\s*(\\d+)\\s*$', r'#\\1', page.page_content, flags=re.MULTILINE)\n",
        "        if '#' in page_content: chapter = int(page_content.split('#')[1].split('\\n')[0])\n",
        "        for k,v in sc_mapping.items():\n",
        "            if v[0] <= page.metadata['page']+1 <= v[1]:\n",
        "                story = k.split('/')[0]\n",
        "                character = k.split('/')[1]\n",
        "                break\n",
        "            story, character = 'Plot', 'None'\n",
        "        page.page_content = page_content\n",
        "        page.metadata['chapter'] = chapter\n",
        "        page.metadata['story'] = story\n",
        "        page.metadata['character'] = character\n",
        "        page.metadata['page'] += 1\n",
        "    return docs\n",
        "\n",
        "pdf_docs = preprocess_pdf(pdf_docs)\n",
        "pdf_docs_copy = pdf_docs.copy()\n",
        "for _ in range(3):\n",
        "    pdf_docs += pdf_docs_copy.copy()\n",
        "print(f'Number of pages: {len(pdf_docs)}')\n",
        "print(f'random page: {pdf_docs[320].page_content[:100]}')\n",
        "print(f'random page metadata: {pdf_docs[320].metadata}')\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,\n",
        "    chunk_overlap=150,\n",
        "    separators=['#', '\\n', '\"', ' ', '']\n",
        ")\n",
        "splits = text_splitter.split_documents(pdf_docs)\n",
        "print(f'Number of splits: {len(splits)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of pages: 2280\nrandom page: last contact, Arundez had aged but little\u2014Sol guessed that\nhe was still in his late twenties. But th\nrandom page metadata: {'source': 'docs/pdf/hyperion.pdf', 'page': 321, 'chapter': 4, 'story': 'Scholar', 'character': 'Sol Weintraub'}\nNumber of splits: 4340\n"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "WedNBTtFMw"
      },
      "source": [
        "# Embedding & Vectorstore\n",
        "\n",
        "### Embedding\n",
        "Langchain provides us with numerous vectorization options, some of most common ones are:\n",
        "1. `HuggingFaceEmbeddings`: Uses the HuggingFace transformers library to generate embeddings\n",
        "2. `OpenAIEmbeddings`: Uses the OpenAI GPT library to generate embeddings\n",
        "\n",
        "We chose to use the `HuggingFaceEmbeddings` as OpenAI was rate limiting the number of requests we could make to their API\n",
        "\n",
        "### Vectorstore\n",
        "A vectorstore is a database of embeddings which corresponds to a set of documents. Langchain provides us with numerous vectorstore options, some of most common ones are:\n",
        "1. `FAISS`: Uses the FAISS library to generate vectorstores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "olTlw6cSCu"
      },
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import os\n",
        "\n",
        "def retrieve_vectorstore(documents):\n",
        "    store_name, _ = os.path.splitext(os.path.basename(documents[0].metadata['source']))\n",
        "    store_path = os.path.join(r'docs/vectorstores', store_name)\n",
        "    if os.path.exists(store_path):\n",
        "        return FAISS.load_local(store_path, HuggingFaceEmbeddings())\n",
        "    else:\n",
        "        vectorstore = FAISS.from_documents(documents=documents, embedding=HuggingFaceEmbeddings())\n",
        "        vectorstore.save_local(store_path)\n",
        "        return vectorstore\n",
        "\n",
        "vectordb = retrieve_vectorstore(splits)\n",
        "query = 'Who are the Outcasters?'\n",
        "print(vectordb.similarity_search('Outcasters?', n=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[Document(page_content='out. Some are waiting forlhe farcaster to be built, but most\\ndon\u2019t believe it\u2019ll happen in time. They\u2019re afraid.\u201d\\n\u201cOf the Ousters?\u201d\\n\u201cThem too,\u201d said Theo, \u201cbut mostly of the Shrike.\u201d\\nThe Consul turned his face from the coolness of the\\ncanopy. \u201cIt\u2019s come south of the Bridle Range then?\u201d\\nTheo laughed without humor. \u201cIt\u2019s everywhere. Or they\u2019r e\\neverywhere. Most people are convinced that there are', metadata={'source': 'docs/pdf/hyperion.pdf', 'page': 128, 'chapter': 2, 'story': 'Plot', 'character': 'None'}), Document(page_content='out. Some are waiting forlhe farcaster to be built, but most\\ndon\u2019t believe it\u2019ll happen in time. They\u2019re afraid.\u201d\\n\u201cOf the Ousters?\u201d\\n\u201cThem too,\u201d said Theo, \u201cbut mostly of the Shrike.\u201d\\nThe Consul turned his face from the coolness of the\\ncanopy. \u201cIt\u2019s come south of the Bridle Range then?\u201d\\nTheo laughed without humor. \u201cIt\u2019s everywhere. Or they\u2019r e\\neverywhere. Most people are convinced that there are', metadata={'source': 'docs/pdf/hyperion.pdf', 'page': 128, 'chapter': 2, 'story': 'Plot', 'character': 'None'}), Document(page_content='out. Some are waiting forlhe farcaster to be built, but most\\ndon\u2019t believe it\u2019ll happen in time. They\u2019re afraid.\u201d\\n\u201cOf the Ousters?\u201d\\n\u201cThem too,\u201d said Theo, \u201cbut mostly of the Shrike.\u201d\\nThe Consul turned his face from the coolness of the\\ncanopy. \u201cIt\u2019s come south of the Bridle Range then?\u201d\\nTheo laughed without humor. \u201cIt\u2019s everywhere. Or they\u2019r e\\neverywhere. Most people are convinced that there are', metadata={'source': 'docs/pdf/hyperion.pdf', 'page': 128, 'chapter': 2, 'story': 'Plot', 'character': 'None'}), Document(page_content='out. Some are waiting forlhe farcaster to be built, but most\\ndon\u2019t believe it\u2019ll happen in time. They\u2019re afraid.\u201d\\n\u201cOf the Ousters?\u201d\\n\u201cThem too,\u201d said Theo, \u201cbut mostly of the Shrike.\u201d\\nThe Consul turned his face from the coolness of the\\ncanopy. \u201cIt\u2019s come south of the Bridle Range then?\u201d\\nTheo laughed without humor. \u201cIt\u2019s everywhere. Or they\u2019r e\\neverywhere. Most people are convinced that there are', metadata={'source': 'docs/pdf/hyperion.pdf', 'page': 128, 'chapter': 2, 'story': 'Plot', 'character': 'None'})]\n"
        }
      ],
      "execution_count": 3
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}